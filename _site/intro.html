<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Introduction | 6.790 Machine Learning</title> <meta name="generator" content="Jekyll v4.3.2" /> <meta property="og:title" content="Introduction" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Graduate Machine Learning course, MIT EECS, fall 2023 term." /> <meta property="og:description" content="Graduate Machine Learning course, MIT EECS, fall 2023 term." /> <link rel="canonical" href="https://gradml.mit.edu/intro.html" /> <meta property="og:url" content="https://gradml.mit.edu/intro.html" /> <meta property="og:site_name" content="6.790 Machine Learning" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Introduction" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","dateModified":"2023-06-15T13:59:04-04:00","description":"Graduate Machine Learning course, MIT EECS, fall 2023 term.","headline":"Introduction","url":"https://gradml.mit.edu/intro.html"}</script> <!-- End Jekyll SEO tag --> <!-- Copied from https://katex.org/docs/browser.html#starter-template --> <link rel="stylesheet" href="/assets/js/katex.min.css"> <!-- The loading of KaTeX is deferred to speed up page rendering --> <script defer src="/assets/js/katex.min.js"> </script> <!-- Automatically display code inside script tags with type=math/tex using KaTeX --> <script defer src="/assets/js/mathtex-script-type.js"> </script> <!-- To automatically render math in text elements, include the auto-render extension: --> <script defer src="/assets/js/auto-render.min.js" onload="renderMathInElement(document.body, { globalGroup: true, trust: true, strict: false, throwOnError: false, });"></script> <!-- The KaTeX default is 1.21em, see https://katex.org/docs/font.html#font-size-and-lengths --> <style> .katex { font-size: 1.21em; } </style> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> 6.790 <br> Machine Learning </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"> <use xlink:href="#svg-menu"></use> </svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">About</a></li><li class="nav-list-item active"><a href="/intro.html" class="nav-list-link active">Introduction</a></li><li class="nav-list-item"><a href="/review.html" class="nav-list-link">Review</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Supervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supervised.html" class="nav-list-link">Supervised Learning</a><ul class="nav-list"><li class="nav-list-item "><a href="/supervised/linearRegression.html" class="nav-list-link">Linear Regression</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Unsupervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/unsupervised.html" class="nav-list-link">Unsupervised Learning</a><ul class="nav-list"><li class="nav-list-item "><button class="nav-list-expander btn-reset" aria-label="toggle items in Graphical category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/unsupervised/graphical.html" class="nav-list-link">Graphical</a><ul class="nav-list"></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reinforcement Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/reinforcement.html" class="nav-list-link">Reinforcement Learning</a><ul class="nav-list"><li class="nav-list-item "><a href="/reinforcement/mdp.html" class="nav-list-link">Markov Decision Process</a></li><li class="nav-list-item "><a href="/reinforcement/bandit.html" class="nav-list-link">Bandits</a></li></ul></li></ul> </nav> <footer class="site-footer"> Last updated: 15-Jun-2023 <br> Edit the <a href="https://shenshen.mit.edu/git/shensquared/gradML">Source Code</a> || <a href="/credit.html">Credit</a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search 6.790 Machine Learning" aria-label="Search 6.790 Machine Learning" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div id="main-content-wrap" class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 id="background"> <a href="#background" class="anchor-heading" aria-labelledby="background"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Background </h1> <p>The term “Machine Learning” was coined by MIT alumnus Arthur Samuel<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> in 1959. It evolved from many fields including Statistical Learning, Pattern Recognition and so on. The goal of machine learning is to make computers “learn” from “data”<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. From an end user’s perspective, it is about understanding your data, make predictions and decisions. Intellectually, it is a collection of models, methods and algorithms that have evolved over more than a half-century now.</p> <p>Historically both disciplines evolved from different perspectives, but with similar end goals. For example, Machine Learning focused on “prediction” and “decisions”. It relied on “patterns” or “model” learnt in the process to achieve it. Computation has played key role in its evolution. In contrast, Statistics, founded by statisticians such as Pearson and Fisher, focused on “model learning”. To understand and explain “why” behind a phenomenon. Probability has played key role in development of the field. As a concrete example, recall the ideal gas law <span class="math inline"><em>P</em><em>V</em> = <em>n</em><em>R</em><em>T</em></span> for Physics. Historically, machine learning only cared about ability to predict <span class="math inline"><em>P</em></span> by knowing <span class="math inline"><em>V</em></span> and <span class="math inline"><em>T</em></span>, did not matter how; on the other hand, Statistics did care about the precise form of the relationship between <span class="math inline"><em>P</em>, <em>V</em></span> and <span class="math inline"><em>T</em></span>, in particular it being linear. Having said that, in current day and age, both disciplines are getting closer and closer, day-by-day, and this class is such an amalgamation.</p> <p>Artificial Intelligence’s stated goal is to <em>mimic human behavior in an intelligent manner</em>, and to do what humans can do but really well, which includes artificial “creativity” and driving cars, playing games, responding to consumer questions, etc. Traditionally, the main tools to achieve these goals are “rules” and “decision trees”. In that sense, Artificial intelligence seeks to create <em>muscle</em> and <em>mind</em> of humans, and <em>mind</em> requires learning from data, i.e. Machine Learning. However, Machine Learning helps learn from data beyond mimicking humans. Having said that, again the boundaries between AI and ML are getting blurry day-by-day.</p> <h1 id="course-structure"> <a href="#course-structure" class="anchor-heading" aria-labelledby="course-structure"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Course Structure </h1> <p>The course contains four parts:</p> <ul> <li><p>Part I. Supervised Learning (L2-11, 43%). Learning from data to predict.</p></li> <li><p>Part II. Unsupervised Learning (L12-18, 30%). Understanding the structure within the data.</p></li> <li><p>Part III. Probabilistic Modeling (L19-20, 9%). Probabilistic view to model complex scenarios.</p></li> <li><p>Part IV. Decision Making (L21-24, 18%). Using data to make decisions.</p></li> </ul> <h2 id="supervised-learning"> <a href="#supervised-learning" class="anchor-heading" aria-labelledby="supervised-learning"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Supervised Learning </h2> <p>The goal of supervised learning is to predict <em>target</em> using <em>input</em> / <em>features</em>, and a model is learned to do so. This can be sufficiently summarized as <span class="math display">$$\text{\textit{target}} = f ( \text{\textit{features}} )$$</span> For classification tasks, the <em>target</em> is categorical or takes discrete values (e.g. hot or cold). For regression tasks, the <em>target</em> takes any real value (e.g. temperature). The model type reflects our <em>belief</em> about the reality and different model leads to different algorithm. The philosophy of supervised learning is: <em>future of the past equals future of the future</em>.</p> <p>Examples of classification include: identify handwritten digits, email spam filtering, detecting malicious network connection based on network log information or predicting whether a client will default on her/his credit based on the client’s features. For example, suppose we have access to a client’s features or attributes in terms of the (credit card) balance and income. Consider Figure <a href="#fig:classify" data-reference-type="ref" data-reference="fig:classify">1</a>. It plots available data with <span class="math inline"><em>X</em></span> axis representing (credit card) balance and <span class="math inline"><em>Y</em></span> axis representing income. The color of the point is blue if <em>no default</em> and brown if <em>default</em>. Pictorially, the classifier is trying to learn a boundary as shown in Figure <a href="#fig:classify" data-reference-type="ref" data-reference="fig:classify">1</a> which separate <em>no default</em> from <em>default</em>.</p> <figure id="fig:classify"> <embed src="classification.pdf" style="width:40.0%" /> <figcaption aria-hidden="true">image</figcaption> </figure> <p>Formally, the data are labeled observations of the following form: <span class="math inline">(<em>x</em><sub>1</sub>,<em>y</em><sub>1</sub>), …, (<em>x</em><sub><em>N</em></sub>,<em>y</em><sub><em>N</em></sub>)</span>. The goal is to learn a model that maps <em>attribute</em> (or <em>feature</em>) <span class="math inline"><em>x</em></span> to <em>label</em> (or <em>target</em>) <span class="math inline"><em>y</em></span> so that given <em>attribute</em> <span class="math inline"><em>x</em></span>, we can predict corresponding <em>unknown (discrete) label</em> <span class="math inline"><em>y</em></span>. That is, to learn a function <span class="math inline"><em>f</em></span> such that <span class="math inline"><em>y</em> = <em>f</em>(<em>x</em>)</span> (and sometimes also what’s the <em>confidence</em>).</p> <p>Various approaches for learning <span class="math inline"><em>f</em></span> can be categorized as</p> <ul> <li><p>Linear: Logistic regression, Support Vector Machine (SVM), Linear Discriminant Analysis (LDA), Perceptron</p></li> <li><p>Non-linear (parametric): Quadratic Discriminant Analysis (QDA), Polynomial, Neural Networks</p></li> <li><p>Non-parametric: Kernels, Nearest Neighbors</p></li> </ul> <p>How to find <span class="math inline"><em>f</em></span>? Among all possible choices of <span class="math inline"><em>f</em></span>, choose the one that <em>fits</em> the data the best. That is, solve optimization: <em>empirical risk minimization (ERM)</em>:</p> <p><span class="math display">$$\text{Minimize } \sum_{i=1}^N \mathrm{loss}\left(y_i,f(x_i)\right) \text{ over all possible } f.$$</span></p> <p>Stochastic Gradient Descent (SGD) is a method to solve this optimization problem. This is where Optimization meets Machine Learning.</p> <p>6.036 (or equivalent undergraduate class) discusses the “How” or “mechanics” of such approaches. In this class, we expect that you know the “How” for much of supervised learning and decision making. That is, more than <span class="math inline">60%</span> of this class. So, what will we do in 6.867 (since <span class="math inline"> &gt; 60%</span> is already done!)?</p> <p>To start with, we will learn “Why” behind the “How”. We will utilize <em>Probability</em> as our formal language. We will discuss estimators and theoretical guarantees, and generalization: does a good model fit on <em>historical data</em> lead to ability to predict <em>future</em>? Finally, we will have 40% of the course discusses unsupervised learning / probabilistic modeling to understand the structure within the data.</p> <p>To understand “Why”, effectively we need to “logically deduce” what we do starting with appropriate goals and axioms. The axioms that are relevant are that of Probability. In particular, to reason about what we do in Machine Learning, we will utilize the language of probability. And probability is entirely based on the three key axioms. Formally, there is a probability space <span class="math inline"><em>Ω</em></span>, events <span class="math inline">ℱ</span> in it, and a probability function <span class="math inline">ℙ : ℱ → [0,1]</span>.</p> <ul> <li><p>Axiom 1. <span class="math inline">ℙ(<em>A</em>) ≥ 0</span>, for all <span class="math inline"><em>A</em> ∈ ℱ</span>.</p></li> <li><p>Axiom 2. <span class="math inline">ℙ(<em>Ω</em>) = 1</span>.</p></li> <li><p>Axiom 3. <span class="math inline">$\mathbb{P}(\cup_{i=1}^\infty E_i)=\sum_{i=1}^\infty \mathbb{P}(E_i)$</span>, if <span class="math inline"><em>E</em><sub><em>i</em></sub> ∩ <em>E</em><sub><em>j</em></sub> = ⌀</span>, for all <span class="math inline"><em>i</em> ≠ <em>j</em></span>.</p></li> </ul> <div class="center"> </div> <p>The above exercise is a simple example of logical deduction starting from the axioms of probability. In a sense, this is what we will do to explain “why”.</p> <p>Before proceeding further, it is important to wonder – “Is it possible to have a different set of probability axioms?” This is a question hotly debated in the first half of last century. At the end of the day, <em>All roads lead to Rome</em>: All sorts of reasonable hypothesis about beliefs / decision making lead to axioms of probability<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p> In the language of probability, both attributes <span class="math inline"><em>X</em></span> and labels <span class="math inline"><em>Y</em></span> are random variables. Especially, <span class="math inline"><em>Y</em></span> is discrete-valued random variable. The conditional distribution <span class="math inline">ℙ(<em>Y</em>|<em>X</em>)</span> is of interest. Suppose labels take value <span class="math inline">1</span> (e.g. default) or <span class="math inline"> − 1</span> (e.g. no default), given attribute <span class="math inline"><em>X</em> = <em>x</em></span>. An ideal classier, also known as <em>Bayes classifier</em>, which in the context of binary classification, predicts $$ <p>$$ The performance metric of interest is mis-classification probability, i.e. <span class="math inline">ℙ(<em>Ŷ</em>(<em>X</em>)≠<em>Y</em>)</span>.</p> <div class="center"> </div> <p>Probabilistic view will help us understand how to choose the loss function and how well our model <em>generalizes</em>. In terms of generalization and overfitting, you should trust your data, but only so much. Consider the following example: We have observations <span class="math inline">(<em>x</em><sub><em>i</em></sub>,<em>y</em><sub><em>i</em></sub>)</span>, <span class="math inline"><em>i</em> = 1, …, <em>n</em></span>. Here attributes <span class="math inline"><em>x</em><sub><em>i</em></sub></span> are points distributed uniformly in the unit square. The label is generated according to the following rule: As sketched in the figure below, <span class="math inline"><em>y</em><sub><em>i</em></sub> = 0</span> when the corresponding <span class="math inline"><strong>x</strong><sub><em>i</em></sub></span> lies in the shaded square and <span class="math inline"><em>y</em><sub><em>i</em></sub> = 1</span> otherwise. The area of the shaded square is <span class="math inline">1/2</span>.</p> <figure> <embed src="square.pdf" style="width:22.0%" /> <figcaption aria-hidden="true">image</figcaption> </figure> <p>Pretend we do not know the true label rule and would like to to find a model to approximate it based on the observations. The function fit, <span class="math display">$$f({x})=\begin{cases} y_i, &amp; \text{if }{x}={x}_i, \\ 0, &amp; \text{otherwise}, \end{cases}$$</span> which assigns every observed points to the correct label <span class="math inline"><em>y</em><sub><em>i</em></sub></span> and assign all unseen points to <span class="math inline">0</span>, is a perfect fit for the observation. However, since the possibility we encounter the same points in the set <span class="math inline">{(<em>x</em><sub><em>i</em></sub>,<em>y</em><sub><em>i</em></sub>), <em>i</em> = 1, …, <em>n</em>}</span> in the future is zero, we will most certainly assign all future points to <span class="math inline">0</span> and this function is simply as bad as “random” function! This is overfitting.</p> <p>In order to prevent overfitting, empirically, we use <em>cross-validation</em> – split data into three parts: <em>train</em>, (<em>validate</em>) and <em>test</em>, or/and <em><span class="math inline"><em>K</em></span>-fold</em> cross-validation. To explain why this the right thing to do, we shall discuss the notion of <em>generalization</em> that utilizes the view that data is generated per an unknown underlying probability distribution. Methodically, we shall use <em>regularization</em> and again probabilistic formalism will help explain why (or why not) it works well. Probabilistic view, again will come to our rescue to explain the <em>implicit</em> regularization that is implemented by modern methods (e.g. ‘dropout’) of neural networks.</p> <p>Some examples of regression include predict wage given age, year, and education level. Formally, the data are labeled observations of the following form: <span class="math inline">(<em>x</em><sub>1</sub>,<em>y</em><sub>1</sub>), …, (<em>x</em><sub><em>N</em></sub>,<em>y</em><sub><em>N</em></sub>)</span>. The goal is to learn a model that maps <em>attribute</em> (or <em>feature</em>) <span class="math inline"><em>x</em></span> to <em>label</em> (or <em>target</em>) <span class="math inline"><em>y</em></span> so that given <em>attribute</em> <span class="math inline"><em>x</em></span>, we can predict corresponding <em>unknown (continuous) label</em> <span class="math inline"><em>y</em></span>. That is, to learn a function <span class="math inline"><em>f</em></span> such that <span class="math inline"><em>y</em> = <em>f</em>(<em>x</em>)</span> (and sometimes also what is the <em>confidence interval</em>).</p> <p>In the language of probability, both attributes <span class="math inline"><em>X</em></span> and labels <span class="math inline"><em>Y</em></span> are random variables. Now, <span class="math inline"><em>Y</em></span> is continuous-valued random variable. The conditional distribution <span class="math inline">ℙ(<em>Y</em>|<em>X</em>)</span> is of interest. Given attribute <span class="math inline"><em>X</em> = <em>x</em></span>, we estimate <span class="math inline"><em>Ŷ</em>(<em>x</em>)</span> to minimize estimation error. One the most common estimation error is <span class="math inline">𝔼[(<em>Y</em>−<em>Ŷ</em>(<em>x</em>))<sup>2</sup>|<em>X</em>=<em>x</em>]</span>, which is minimized by <span class="math inline"><em>Ŷ</em>(<em>x</em>) = 𝔼[<em>Y</em>|<em>X</em>=<em>x</em>]</span>. Finally, we should determine <em>predictive</em> distribution. <span class="math inline">𝔼[<em>Y</em>|<em>X</em>=<em>x</em>]</span> is unknown. The model fit for regression means to find the best fit for <span class="math inline"><em>f</em>(<em>x</em>) ≈ 𝔼[<em>Y</em>|<em>X</em>=<em>x</em>]</span> using observed data.</p> <div class="center"> </div> <h2 id="unsupervised-learning"> <a href="#unsupervised-learning" class="anchor-heading" aria-labelledby="unsupervised-learning"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Unsupervised Learning </h2> <p>In unsupervised learning, there is no <em>target</em>. Only <em>input</em> / <em>features</em> are given. The goal is to learn the data distribution. In this course, we are going to cover topics such as dimensionality reduction, matrix estimation, clustering and mixture distribution, and feature extraction (topic model and deep generative model) from unstructured data such as text, audio or image, or for complexity reduction. Examples of unsupervised learning: Finding the principal component of DNA data (dimensionality reduction) <span class="citation" data-cites="Novembre2008">[@Novembre2008]</span>, movie recommendation (matrix estimation), analyzing topics in documents (feature extraction: topic model), generating fake faces of celebrities (feature extraction: deep generative model).</p> <h2 id="probabilistic-modeling"> <a href="#probabilistic-modeling" class="anchor-heading" aria-labelledby="probabilistic-modeling"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Probabilistic Modeling </h2> <p>Two important topics in probabilistic modeling is incorporating prior knowledge from Bayesian perspective and sampling from distribution when probabilistic model is complex.</p> <p>Most of the key tasks in machine learning are inference tasks. For example, in prediction we need to infer <span class="math inline">ℙ(<em>Y</em>|<em>X</em>)</span>. In model learning, we need to infer <span class="math inline">ℙ(parameters|data)</span>. The Bayes’ rule states that <span class="math display">$$\underset{\text{posterior}}{\mathbb{P}(\text{parameters}|\text{data})}\propto \underset{\text{likelihood}}{\mathbb{P}(\text{data}|\text{parameters})}\times \underset{\text{prior}}{\mathbb{P}(\text{parameters})}$$</span> The key question is how to select <em>prior</em>? This is the <em>prior</em> knowledge of the world. One of the classical priors is Gaussian distribution, which for example, leads to ridge regularization in regression.</p> <p>A probability distribution can be complex. It may have succinct representation but no closed form formula, and hence difficult to evaluate. For example, we may know <span class="math display">$$\mathbb{P}(X=x)\propto \exp(f(x))=\frac{1}{Z}\exp(f(x)),$$</span> where <span class="math display"><em>Z</em> = ∫exp (<em>f</em>(<em>x</em>))<em>d</em><em>x</em>.</span> This integration can be very hard to evaluate for a general <span class="math inline"><em>f</em>(<em>x</em>)</span>. The key algorithm to evaluate on such complex distributions is Markov Chain Monte Carlo (MCMC)<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> It has specific forms such as Gibbs sampling and Metropolis-Hastings. MCMC works for generic form of distribution.</p> <h2 id="decision-making"> <a href="#decision-making" class="anchor-heading" aria-labelledby="decision-making"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Decision Making </h2> <p>In data driven decision making (in presence of uncertainty), we need to learn the model of uncertainty, given observations. The goal is to make “optimal” decision with respect to a long-term objective. The decision vs information <em>timescale</em> are critically important. The following diagram summarizes the framework of decision making,</p> <figure> <embed src="dm.pdf" style="width:50.0%" /> <figcaption aria-hidden="true">image</figcaption> </figure> <p>The two key <em>timescales</em> are state or environment dynamics, and information dynamics. Depending on the two timescales, there are methods / approaches including optimizing given model of uncertainty, Markov decision process, and reinforcement learning.</p> <div class="table-wrapper"><table> <thead> <tr class="header"> <th></th> <th style="text-align: left;">State Dynamics</th> <th style="text-align: left;">Information Dynamics</th> </tr> </thead> <tbody> <tr class="odd"> <td>Optimizing Given Model of Uncertainty</td> <td style="text-align: left;">No change (or extremely slow)</td> <td style="text-align: left;">Lots of historical information</td> </tr> <tr class="even"> <td>Markov Decision Process</td> <td style="text-align: left;">High</td> <td style="text-align: left;">Lots of historical information</td> </tr> <tr class="odd"> <td>Reinforcement Learning</td> <td style="text-align: left;">High</td> <td style="text-align: left;">Minimal information, learn as you go</td> </tr> </tbody> </table></div> <p>The fundamental challenge in reinforcement learning is <em>explore vs exploit</em>. An example of poor decision is it is difficult to find blue sweater for young girls. To maximize profit (<em>exploit</em>), clothes makers choose not to make or make very few blue sweaters such that blue sweaters are hard to find and expensive. An important application of reinforcement learning is automated game player. We’ll do a case study on AlphaGoZero.</p> <h2 id="and-then-what-is-not-cover-but-of-interest"> <a href="#and-then-what-is-not-cover-but-of-interest" class="anchor-heading" aria-labelledby="and-then-what-is-not-cover-but-of-interest"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> And then, What Is Not Cover, But Of Interest </h2> <p>We may not be able to cover the following interesting topics in machine learning:</p> <ul> <li><p>Active Learning, actively obtain data as each data point is expensive.</p></li> <li><p>Transfer Learning, transfer data collected for one task to other learning task.</p></li> <li><p>Semi-supervised Learning, supervised setting with (additional) unsupervised data.</p></li> <li><p>Causal inference, Hypothesis testing, ...</p></li> </ul> <p>But hopefully, things you’ll learn this in course will provide systematic foundations to approach these topics.</p> <h1 id="model-selection-an-example"> <a href="#model-selection-an-example" class="anchor-heading" aria-labelledby="model-selection-an-example"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Model Selection: An Example </h1> <p>We have data <span class="math inline"><em>x</em><sub>1</sub>, …, <em>x</em><sub><em>N</em></sub></span> sampled from a distribution. The goal is to learn the distribution. The assumption is that the data is generated from a Gaussian distribution <span class="math inline">𝒩(<em>μ</em>,<em>σ</em><sup>2</sup>)</span>. Then the refined goal is to learn the mean and variance. How to learn (parameters, mean and variance)?</p> <p>A common method is maximum likelihood (ML), that is, choose the parameters that maximize <span class="math inline">ℙ(data|parameters)</span>. In this problem, to choose mean, variance from samples, the likelihood is</p> <p><span class="math display">$$\begin{aligned} \mathbb{P}\left(x_1,\ldots,x_N|\mu,\sigma^2\right)=&amp;\prod_{i=1}^N\mathbb{P}\left(x_i|\mu,\sigma^2\right) \\ =&amp;\prod_{i=1}^N \frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(x_i-\mu)^2}{2\sigma^2}\right). \end{aligned}$$</span></p> <p>Maximizing likelihood is same as maximizing logarithm of likelihood. This leads to <span class="math display">max<sub><em>μ</em>, <em>σ</em><sup>2</sup></sub><em>g</em>(<em>μ</em>,<em>σ</em><sup>2</sup>),</span> where <span class="math display">$$g(\mu,\sigma^2)=-\frac{1}{2\sigma^2}\sum_{i=1}^N(x_i-\mu)^2-N\ln\sigma -N\ln\sqrt{2\pi}.$$</span> This is an optimization problem and its solution is what we desire. For such reasons, optimization is an integral part of Machine Learning.</p> <p>The ML estimation for variance (and standard deviation) is biased. This leads to the Bessel correction for variance: <span class="math display">$$\tilde{\sigma}^2_{\rm ML}=\frac{1}{N-1}\sum_{i=1}^N (x_i-\mu_{\rm ML})^2.$$</span></p> <p>{: .highlight } A paragraph</p> <aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr /> <ol> <li id="fn1"><p>See https://g.co/kgs/Lj3v3k to read more about Arthur Samuel.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li> <li id="fn2"><p>What is learning? Some food for thought: <a href="https://goo.gl/5R1m4S" class="uri">https://goo.gl/5R1m4S</a>.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li> <li id="fn3"><p>A good set of readings include <span class="citation" data-cites="Cox1946">[@Cox1946]</span>, <span class="citation" data-cites="Savage2012">[@Savage2012]</span> and <span class="citation" data-cites="de2017">[@de2017]</span><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li> <li id="fn4"><p>MCMC is one of the top 10 algorithms of all time <span class="citation" data-cites="top10">[@top10]</span>. Other algorithms include quicksort and fast Fourier transform.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li> </ol> </aside> </main> </div> </div> <div class="search-overlay"></div> </div> </body> </html> <script src="https://hypothes.is/embed.js" async></script>
