<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Classification Foundation | 6.790 Machine Learning</title> <meta name="generator" content="Jekyll v4.3.2" /> <meta property="og:title" content="Classification Foundation" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Graduate Machine Learning course, MIT EECS, fall 2023 term." /> <meta property="og:description" content="Graduate Machine Learning course, MIT EECS, fall 2023 term." /> <link rel="canonical" href="https://gradml.mit.edu/supervised/classification_foundation/" /> <meta property="og:url" content="https://gradml.mit.edu/supervised/classification_foundation/" /> <meta property="og:site_name" content="6.790 Machine Learning" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Classification Foundation" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","dateModified":"2023-06-16T04:45:21-04:00","description":"Graduate Machine Learning course, MIT EECS, fall 2023 term.","headline":"Classification Foundation","url":"https://gradml.mit.edu/supervised/classification_foundation/"}</script> <!-- End Jekyll SEO tag --> <!-- Copied from https://katex.org/docs/browser.html#starter-template --> <link rel="stylesheet" href="/assets/js/katex.min.css"> <!-- The loading of KaTeX is deferred to speed up page rendering --> <script defer src="/assets/js/katex.min.js"> </script> <!-- Automatically display code inside script tags with type=math/tex using KaTeX --> <script defer src="/assets/js/mathtex-script-type.js"> </script> <!-- To automatically render math in text elements, include the auto-render extension: --> <script defer src="/assets/js/auto-render.min.js" onload="renderMathInElement(document.body, { globalGroup: true, trust: true, strict: false, throwOnError: false, });"></script> <!-- The KaTeX default is 1.21em, see https://katex.org/docs/font.html#font-size-and-lengths --> <style> .katex { font-size: 1.21em; } </style> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> 6.790 <br> Machine Learning </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"> <use xlink:href="#svg-menu"></use> </svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">About</a></li><li class="nav-list-item"><a href="/calendar/" class="nav-list-link">Syllabus / Calendar</a></li><li class="nav-list-item"><a href="/schedule/" class="nav-list-link">Weekly Schedule</a></li><li class="nav-list-item"><a href="/intro/" class="nav-list-link">Introduction</a></li><li class="nav-list-item"><a href="/review/" class="nav-list-link">Background/Review</a></li><li class="nav-list-item active"><button class="nav-list-expander btn-reset" aria-label="toggle items in Supervised Learning category" aria-pressed="true"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supervised/" class="nav-list-link">Supervised Learning</a><ul class="nav-list"><li class="nav-list-item active"><a href="/supervised/classification_foundation/" class="nav-list-link active">Classification Foundation</a></li><li class="nav-list-item "><a href="/supervised/DiscriminativeGenerative/" class="nav-list-link">Discriminative vs Generative Classification</a></li><li class="nav-list-item "><a href="/supervised/learnability_and_vc/" class="nav-list-link">Learnability and VC Dimension</a></li><li class="nav-list-item "><a href="/supervised/linearRegression/" class="nav-list-link">Linear Regression</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Unsupervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/unsupervised/" class="nav-list-link">Unsupervised Learning</a><ul class="nav-list"><li class="nav-list-item "><button class="nav-list-expander btn-reset" aria-label="toggle items in Graphical Models category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/unsupervised/graphical/" class="nav-list-link">Graphical Models</a><ul class="nav-list"></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reinforcement Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/reinforcement/" class="nav-list-link">Reinforcement Learning</a><ul class="nav-list"><li class="nav-list-item "><a href="/reinforcement/mdp/" class="nav-list-link">Markov Decision Process</a></li><li class="nav-list-item "><a href="/reinforcement/value_bellman/" class="nav-list-link">Value functions and Bellman</a></li><li class="nav-list-item "><a href="/reinforcement/bandit/" class="nav-list-link">Bandits</a></li><li class="nav-list-item "><a href="/reinforcement/policy_gradient/" class="nav-list-link">Policy Gradient</a></li><li class="nav-list-item "><a href="/reinforcement/deepRL/" class="nav-list-link">Deep Reinforcement Learning</a></li></ul></li></ul> </nav> <footer class="site-footer"> <a href="/credit">Acknowledgement</a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search 6.790 Machine Learning" aria-label="Search 6.790 Machine Learning" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://canvas.mit.edu/" class="site-button" target="_blank" rel="noopener noreferrer" > Canvas </a> </li> <li class="aux-nav-list-item"> <a href="https://piazza.com" class="site-button" target="_blank" rel="noopener noreferrer" > Piazza </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/supervised/">Supervised Learning</a></li> <li class="breadcrumb-nav-list-item"><span>Classification Foundation</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="overview"> <a href="#overview" class="anchor-heading" aria-labelledby="overview"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Overview </h1> <p>The aim of this lecture is to establish basic terminology and definitions useful for studying classification. We will discuss two basic classifiers: (i) Bayes; and (ii) Nearest Neighbors. The former is an abstract classifier used to understands the theoretical limits of classification, while the latter is a basic technique that one can use without having to use any specific “training algorithm”. We will see performance measures as well as some theoretical results regarding the classifiers introduced, along with some of the intuition behind when and why they work. Thereafter, we will motivate the idea of Empirical Risk Minimization (ERM), which is a leading paradigm for training classifiers in machine learning. We will discuss strengths and weaknesses of this framework, including the key ideas of “over-fitting” and “inductive bias”, as well as some standard trade-offs that one should be aware of when performing classification.</p> <h1 id="notations-setup"> <a href="#notations-setup" class="anchor-heading" aria-labelledby="notations-setup"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Notations, Setup </h1> <p>We start with notations, setup that are we assume throughout the course for classification or more generally for supervised learning.</p> <ul> <li><p><strong>Data domain</strong>: An arbitrary set <span class="math inline">𝒳</span> from which our training and test data are drawn. As often is the case, <span class="math inline">𝒳 = ℝ<sup><em>d</em></sup></span>. For instance, if we assume that the members of <span class="math inline">𝒳</span> are represented via <em>feature vectors</em>; we may write <span class="math inline"><em>Φ</em>(<em>x</em>)</span> to emphasize the encoding of a data point <span class="math inline">$x \in \cal X$</span> as a feature vector in <span class="math inline">ℝ<sup><em>d</em></sup></span>.</p></li> <li><p><strong>Label domain</strong>: A discrete set <span class="math inline">𝒴</span>; e.g., <span class="math inline">{0, 1}</span> or <span class="math inline">{ − 1, 1}</span>. It is important to <em>not</em> interpret these <span class="math inline">0</span> and <span class="math inline">1</span> as “numbers,” but rather as “classes” or categorical variables. For the setting of regression, as we shall see, the label domain <span class="math inline">𝒴</span> could be continuous, e.g. <span class="math inline">𝒴 = [0,1]</span> or <span class="math inline">ℝ</span>.</p></li> <li><p><strong>Training data</strong>: A finite collection <span class="math inline"><em>S</em> = {(<em>x</em><sub>1</sub>,<em>y</em><sub>1</sub>),…,(<em>x</em><sub><em>N</em></sub>,<em>y</em><sub><em>N</em></sub>)}</span> of (data, label) pairs drawn from <span class="math inline">𝒳 × 𝒴</span>.</p></li> <li><p><strong>Data distribution</strong>: A joint distribution <span class="math inline">ℙ</span> on <span class="math inline">𝒳 × 𝒴</span>. An <em>important assumption</em> made throughout standard supervised machine learning is that while <span class="math inline">ℙ</span> is unknown, it is fixed.   We write <span class="math inline">(<em>X</em>,<em>Y</em>)</span> to denote a random variable with <span class="math inline"><em>X</em></span> taking values in <span class="math inline">𝒳</span> and <span class="math inline"><em>Y</em></span> taking values in <span class="math inline">𝒴</span>.</p></li> </ul> <p><strong>Classifier</strong>. With these definitions, we are now ready to define a <em>classifier</em>; formally, it is simply a prediction rule <span class="math display"><em>h</em> : 𝒳 → 𝒴,</span> that is, a map from the data domain to the label domain. We will write <span class="math inline"><em>h</em><sub><em>S</em></sub></span> to emphasize dependence of the classifier <span class="math inline"><em>h</em></span> on training data. We will abuse the notation by denoting <span class="math inline"><em>h</em></span> as a hypothesis, prediction rule, or classifier, but we do hope that the precise meaning will be clear from the context.</p> <p>Suppose we have a candidate classifier <span class="math inline"><em>h</em></span>. We need some way to measure its performance or simply to provide us with a mathematical guideline on “what does it mean to train?” Indeed, the goal of supervised learning is to use training data to help train a classifier that works well on unseen test data. To quantify what “works well”, we describe a key idea below.</p> <p><strong>Measuring success</strong>. We consider a quantity that measures the error of classifier. This quantity is called <strong>risk</strong>, which is also known as the <em>generalization error</em>: <span class="math display"><em>L</em>(<em>h</em>) ≡ <em>L</em><sub>ℙ</sub>(<em>h</em>) := ℙ(<em>h</em>(<em>X</em>)≠<em>Y</em>).</span> In words, the risk <a href="#eq:1" data-reference-type="eqref" data-reference="eq:1">[eq:1]</a> of a classifier <span class="math inline"><em>h</em></span> is the probability of randomly choosing a pair <span class="math inline">(<em>X</em>,<em>Y</em>) ∼ ℙ</span> for which <span class="math inline"><em>h</em>(<em>X</em>) ≠ <em>Y</em></span>. The central goal of supervised learning is to learn a classifier <span class="math inline"><em>h</em></span> using training data so that it has low risk—ideally, a classifier that is guaranteed to minimize <a href="#eq:1" data-reference-type="eqref" data-reference="eq:1">[eq:1]</a>.</p> <h1 id="sub:bayes_classifier"> <a href="#sub:bayes_classifier" class="anchor-heading" aria-labelledby="sub:bayes_classifier"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Bayes Classifier </h1> <p>Given the goal of task is to minimize the risk <a href="#eq:1" data-reference-type="eqref" data-reference="eq:1">[eq:1]</a> (i.e., the chance of being wrong on unseen data), at least in principle there is a simple strategy that can help attain this risk. Indeed, suppose we know the distribution <span class="math inline">ℙ</span> as per which data is generated, then intuitively it makes sense to pick the most likely class given the observation (notice, this intuition not limited to binary classification). This intuitive idea is exactly the idea behind the so-called Bayes classifier. Before describing the Bayes classifier formally, let us introduce some additional notation; we limit our description to binary classification for ease of exposition.</p> <p><strong>Class conditional distribution</strong>: Let <span class="math inline">𝒴 = {0, 1}</span>. We define <span class="math display"><em>η</em>(<em>x</em>) := ℙ(<em>Y</em>=1|<em>X</em>=<em>x</em>) = 𝔼[<em>Y</em>|<em>X</em>=<em>x</em>],</span> which describes the posterior probability of the data being in class <span class="math inline">1</span> given that you have observed <span class="math inline"><em>x</em></span>. The Bayes classifier <span class="math inline"><em>h</em><sup>*</sup>(<em>x</em>)</span> is defined by the rule: <span class="math display">$$\label{eq:3} h^{*}(x) := \begin{cases} 1, &amp;\text{if}\ \eta(x)=\mathbb{P}(Y=1 | X=x)&gt;\frac{1}{2}\\ 0, &amp;\text{otherwise}. \end{cases}$$</span> The classifier <a href="#eq:3" data-reference-type="eqref" data-reference="eq:3">[eq:3]</a> predicts label <span class="math inline">1</span> if the conditional probability of being in class <span class="math inline">1</span> is bigger than half. Remarkably, it can be shown that this simple classifier actually performs as good as any other classifier in terms of minimizing the risk, as established formally via the following theorem (stated formally for <span class="math inline">𝒳 = ℝ<sup><em>d</em></sup></span> for simplicity).</p> <div id="thm:bayes" class="theorem"> <p><strong>Theorem 1</strong> (BC optimality). <em>For any classifier <span class="math inline"><em>h</em> : ℝ<sup><em>d</em></sup> → {0, 1}</span>, <span class="math inline"><em>L</em>(<em>h</em><sup>*</sup>) ≤ <em>L</em>(<em>h</em>)</span>.</em></p> </div> <div class="proof"> <p><em>Proof.</em> Given <span class="math inline"><em>X</em> = <em>x</em></span>, the conditional error probability of any classifier <span class="math inline"><em>h</em></span> may be written as: <span class="math display">$$\begin{aligned} {\quad \mathbb{P}\left(h(X) \neq Y | X=x\right)} &amp;{=1-\mathbb{P}\left(Y=h(X) | X=x\right)} \\ &amp; {=1-\left(\mathbb{P}\left(Y=1, h(X)=1 | X=x\right)+\mathbb{P}\left(Y=0, h(X)=0 | X=x\right)\right)} \\ &amp; =1-\left( [\![h(x)=1]\!] \mathbb{P}\left(Y=1 | X=x\right)+[\![h(x)=0]\!] \mathbb{P}\left(Y=0 | X=x\right)\right)\\ &amp; =1- \left([\![h(x)=1]\!] \eta(x)+ [\![h(x)=0]\!] (1-\eta(x))\right) \end{aligned}$$</span> where <span class="math inline">[ [⋅] ]</span> is the Iverson bracket, i.e. <span class="math inline">[ [<em>z</em>] ] = 1</span> if <span class="math inline"><em>z</em>=</span> ‘true’ and <span class="math inline">0</span> if <span class="math inline"><em>z</em>=</span> ‘false’. Thus, for every <span class="math inline"><em>x</em> ∈ ℝ<sup><em>d</em></sup></span>, we have: <span class="math display">$$\begin{aligned} &amp; \mathbb{P}\left(h(X) \neq Y | X=x\right) - \mathbb{P}\left(h^{*}(X) \neq Y | X=x\right) \\ &amp; \qquad = \eta(x)\left([\![h^{*}(x)=1]\!]-[\![h(x)=1]\!]\right) + \left(1-\eta(x)\right) \left([\![h^{*}(x)=0]\!]-[\![h(x)=0]\!]\right). \end{aligned}$$</span> Since <span class="math inline">[ [<em>h</em><sup>*</sup>(<em>x</em>)=0] ] = 1 − [ [<em>h</em><sup>*</sup>(<em>x</em>)=1] ]</span>, the above equals to <span class="math inline">(2<em>η</em>(<em>x</em>)−1)([ [<em>h</em><sup>*</sup>(<em>x</em>)=1] ]−[ [<em>h</em>(<em>x</em>)=1] ])</span> which is non-negative based on the definition of <span class="math inline"><em>h</em><sup>*</sup></span> (<span class="math inline"><em>η</em>(<em>x</em>) &gt; 1/2 ⇔ [ [<em>h</em><sup>*</sup>(<em>x</em>)=1] ] = 1</span>). Thus we have <span class="math display">∫ ℙ(<em>h</em>(<em>X</em>)≠<em>Y</em>|<em>X</em>=<em>x</em>)<em>d</em>ℙ(<em>x</em>) ≥ ∫ ℙ(<em>h</em><sup>*</sup>(<em>X</em>)≠<em>Y</em>|<em>X</em>=<em>x</em>)<em>d</em>ℙ(<em>x</em>).</span> or equivalently, <span class="math inline">ℙ(<em>h</em>(<em>X</em>)≠<em>Y</em>) ≥ ℙ(<em>h</em><sup>*</sup>(<em>X</em>)≠<em>Y</em>)</span>. ◻</p> </div> <p>Related to the manipulations of Theorem <a href="#thm:bayes" data-reference-type="ref" data-reference="thm:bayes">1</a> is a helpful exercise below:</p> <p><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p> <div class="center"> </div> <p>. Per Theorem <a href="#thm:bayes" data-reference-type="ref" data-reference="thm:bayes">1</a>, we have found the best possible classifier. But it is <em>idealized</em>.</p> <p><span style="color: cdarkred"><strong>Question:</strong></span> What makes the Bayes classifier idealized?<br /> <span style="color: cdarkred"><strong>Answer</strong></span>: The Bayes classifier assumes that we have access to <span class="math inline">ℙ(<em>X</em>,<em>Y</em>)</span>, but we almost never have access to this joint distribution. So the importance of Bayes classifier is more conceptual: if we had complete power and knew the distribution of the data we would know how to construct the best possible classifier.</p> <p>Because we almost never have access to the true underlying joint distribution, let us now take a look at a fundamental approach to classification that <em>seems</em> distribution-free, namely, the method of nearest neighbors (NN).</p> <h1 id="nearest-neighbors"> <a href="#nearest-neighbors" class="anchor-heading" aria-labelledby="nearest-neighbors"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Nearest Neighbors </h1> <p>This approach is akin to taking a view opposite to the Bayes classifier: whereas Bayes assumes full knowledge and takes advantage of the data distribution, Nearest neighbors (NN) ignores the underlying probability distribution. At a high level, the NN method is based on the belief that features that are used to describe the data are relevant to the labelings in a way that makes “close by” points likely to have the same label.</p> <p>NN is one of the simplest possible classifiers, where the training process is essentially to memorize the training data. Then during testing, for a given point <span class="math inline"><em>x</em></span>, it finds the <span class="math inline"><em>k</em></span> points in training data nearest to <span class="math inline"><em>x</em></span> and predicts a label by taking (weighted) majority label over these <span class="math inline"><em>k</em></span> points. Precisely, given training data <span class="math inline"><em>S</em> = {(<em>x</em><sub><em>i</em></sub>,<em>y</em><sub><em>i</em></sub>)|1≤<em>i</em>≤<em>N</em>}</span>, define <span class="math display">NN<sub><em>k</em></sub>(<em>x</em>) := {<em>j</em>|1≤<em>j</em>≤<em>k</em>,<em>x</em><sub><em>j</em></sub> is within <em>k</em> closest to <em>x</em>}.</span> Notice that <span class="math inline">NN<sub>1</sub>(<em>x</em>) = argmin<sub>1 ≤ <em>i</em> ≤ <em>N</em></sub>dist (<em>x</em>,<em>x</em><sub><em>i</em></sub>)</span>. Then, the <span class="math inline"><em>k</em></span>-NN classifier <span class="math display">$$\begin{aligned} h_{k\text{-NN}}(x) &amp; = \frac{1}{k} \sum_{\ell \in \mathrm{NN}_{k}(x)} y_\ell. \end{aligned}$$</span></p> <h2 id="nn-and-bayes"> <a href="#nn-and-bayes" class="anchor-heading" aria-labelledby="nn-and-bayes"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> NN and Bayes </h2> <figure> <img src="./knn.png" style="width:30.0%" alt="k-NN can learn complex nonlinear classifiers (Image Credit: Elements of Statistical Learning Theory)" /> <figcaption aria-hidden="true"><span class="math inline"><em>k</em></span>-NN can learn complex nonlinear classifiers (Image Credit: Elements of Statistical Learning Theory)</figcaption> </figure> <p>Despite its simplicity, NN is capable of learning complex nonlinear classifiers. Precisely, the risk of NN <span class="math display">$$\begin{aligned} L_{k\text{-NN}} &amp; = \mathbb{P}(h_{k\text{-NN}}(X) \neq Y). \end{aligned}$$</span> NN classifier has excellent asymptotic performance even for <span class="math inline"><em>k</em> = 1</span> as stated below (see <span class="citation" data-cites="cover1967nearest">[@cover1967nearest]</span> for more details).</p> <div id="thm:nn" class="theorem"> <p><strong>Theorem 2</strong>. <em>Let <span class="math inline">𝒳 ⊂ ℝ<sup><em>d</em></sup>, <em>d</em> ≥ 1</span>. Let <span class="math inline"><em>η</em></span> be continuous. Then, <span class="math display">$$\begin{aligned} \lim_{n\to\infty} L_{1\text{-NN}} &amp; = 2 \mathbb{E}\big[\eta(X) (1-\eta(X))\big] ~\leq~2 \mathbb{E}\big[\min\{\eta(X), 1-\eta(X)\}] ~=~ 2 L^*. \end{aligned}$$</span></em></p> </div> <p>That is, with large number of data points, even <span class="math inline">1</span>-NN algorithm has risk that is within factor <span class="math inline">2</span> of the optimal risk.</p> <div class="proof"> <p><em>Proof.</em> Given <span class="math inline"><em>X</em> = <em>x</em></span>, let <span class="math inline"><em>X</em>′(<em>n</em>)</span> the closest data point to <span class="math inline"><em>x</em></span> amongst given <span class="math inline"><em>n</em></span> observations. Then due to <span class="math inline">𝒳 ⊂ ℝ<sup><em>d</em></sup></span> (i.e. complete, separable metric space), it can be argued that <span class="math inline"><em>X</em>′(<em>n</em>) → <em>x</em></span> as <span class="math inline"><em>n</em> → ∞</span> with probability <span class="math inline">1</span>. Further, <span class="math inline"><em>η</em></span> is continuous. Therefore, <span class="math inline"><em>η</em>(<em>X</em>′(<em>n</em>)) → <em>η</em>(<em>x</em>)</span> as <span class="math inline"><em>n</em> → ∞</span> with probability <span class="math inline">1</span>. Let <span class="math inline"><em>Y</em>′(<em>n</em>)</span> be the label observed associated <span class="math inline"><em>X</em>′(<em>n</em>)</span>. Then, <span class="math display">$$\begin{aligned} \mathbb{P}(h_{1\text{-NN}}(x) \neq Y | X = x) &amp; = \mathbb{P}(Y'(n) \neq Y | X = x) \\ &amp; = \mathbb{P}(Y'(n) = 1, Y = 0| X = x) + \mathbb{P}(Y'(n) = 0, Y = 1| X = x) \\ &amp; \stackrel{(a)}{=} \mathbb{P}(Y'(n) = 1 | X = x) \mathbb{P}( Y = 0 | X = x) + \mathbb{P}(Y'(n) = 0 | X = x) \mathbb{P}( Y = 1| X = x) \\ &amp; = \eta(X'(n)) (1-\eta(x)) + (1-\eta(X'(n)) \eta(x) \\ &amp; \to 2 \eta(x) (1-\eta(x)) \\ &amp; \stackrel{(b)}{=} 2 \min\{\eta(x), 1-\eta(x)\} \max\{\eta(x), 1-\eta(x)\} \\ &amp; \stackrel{(c)}{\leq} 2 \min\{\eta(x), 1-\eta(x)\}. \end{aligned}$$</span> In above, (a) follows from the fact that <span class="math inline"><em>Y</em>′(<em>n</em>)</span> and <span class="math inline"><em>Y</em></span> are generated independently per our generative model; (b) from that the fact for <span class="math inline"><em>α</em>, <em>β</em> ∈ ℝ</span> we have <span class="math inline"><em>α</em><em>β</em> = min {<em>α</em>, <em>β</em>}max {<em>α</em>, <em>β</em>}</span>; and (c) from the fact that <span class="math inline"><em>η</em>(<em>x</em>) ∈ [0,1]</span> as it is probability. Then, the claim of theorem follows by recalling that the Bayes risk <span class="math inline"><em>L</em><sup>*</sup> = 𝔼[min{<em>η</em>(<em>X</em>),1−<em>η</em>(<em>X</em>)}]</span>. ◻</p> </div> <p>Theorem <a href="#thm:nn" data-reference-type="ref" data-reference="thm:nn">2</a> provides asymptotic guarantee for <span class="math inline">1-NN</span> algorithm. But in practice, we have only finite amount of data. A refined analysis (cf. see <span class="citation" data-cites="chen-shah">[@chen-shah Chapter 3]</span>) suggests that if <span class="math inline">𝒳 ⊂ ℝ<sup><em>d</em></sup></span>, <span class="math inline"><em>η</em></span> is <span class="math inline"><em>α</em> ≥ 1</span>-Holder continuous (see <span class="citation" data-cites="chen-shah">[@chen-shah]</span> for precise definition, for example), then for any <span class="math inline"><em>ε</em> ∈ (0,1)</span>, for <span class="math inline"><em>k</em>-NN</span> with <span class="math inline"><em>k</em> = <em>Θ</em>(<em>ε</em><sup>−2</sup>)</span> and <span class="math inline">$n = \Theta(\varepsilon^{-\frac{d}{\alpha} + 3} \log \varepsilon^{-1})$</span>, the algorithm find approximation of <span class="math inline"><em>η</em></span> that is within <span class="math inline"><em>ε</em></span> error on average. This leads to good approximation of Bayes risk.</p> <div class="center"> </div> <p>The nearest neighbor approach is powerful in that it works for any (reasonable) setting. For that reason, it is called non-parametric method. However, it comes at the cost of not utilizing the potentially simpler, a priori known structure in the data. For that reason, it suffers from requiring large amount of data (there is no ‘free lunch’). However, if we have prior knowledge about the model class, it may make sense to incorporate it. And this is where the framework of Empirical Risk Minimization through incorporating “inductive bias” comes handy and we describe that next.</p> <h1 id="empirical-risk-minimization"> <a href="#empirical-risk-minimization" class="anchor-heading" aria-labelledby="empirical-risk-minimization"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Empirical Risk Minimization </h1> <p>ERM makes the following trade-off: we accept that we do not know the full distribution (unlike the Bayes Classifier), but we do get to see the training data and we are not ignoring the training distribution (unlike NN classifiers). By not throwing away the training distribution, we can at least measure the error incurred by a classifier on the training data, aka the <em>training error</em> or <em>empirical risk</em>: <span class="math display">$$L_{S}(h) :=\frac{1}{N} \big|\left\{i \in[N] | h\left(x_{i}\right) \neq y_{i}\right\} \big|.$$</span> As the name suggests, the paradigm of Empirical Risk Minimization (ERM) seeks a predictor that minimizes <span class="math inline"><em>L</em><sub><em>S</em></sub>(<em>h</em>)</span>. In other words, it uses <span class="math inline"><em>L</em><sub><em>S</em></sub>(<em>h</em>)</span> as a proxy for the true risk. Notice how this implies that while we do not throw away any “knowledge” gained from the training data, we are implicitly assuming the distribution of the training data is “representative” of the true underlying distribution.</p> <h2 id="sub:over_fitting"> <a href="#sub:over_fitting" class="anchor-heading" aria-labelledby="sub:over_fitting"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Over-fitting </h2> <p>Of course, greedily minimizing the empirical loss can lead to overfitting. If we get “unlucky” where the training data is not true example of the actual distribution, then over-fitting would lead to high error on unseen data, which is obviously problematic.</p> <div class="center"> </div> <p><span style="color: cdarkred"><strong>Food for thought</strong></span>: What is over-fitting? Essentially memorizing the training data. But is it necessarily bad? In itself not necessarily a bad idea; some argue that deep neural nets are essentially memorizing, yet they generalize well. More on this later today and also in Lecture 7.</p> <h2 id="sub:inductive_bias"> <a href="#sub:inductive_bias" class="anchor-heading" aria-labelledby="sub:inductive_bias"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Inductive bias </h2> <p>Since it is so easy to overfit when minimizing empirical risk, we search for settings where overfitting can be alleviated. One idea is to introduce the so-called “inductive bias,” which restricts the family of classifiers that we search over; this choice is made <em>in advance</em> before having seen any training data. Common examples of inductive-bias include linear models, neural networks, random forests, etc. The reason this is called a bias is because we are limiting ourselves to a “pre-determined” hypothesis class that we chose (i.e. our “bias” is present). And by doing so, it may not have any classifier that perfectly fits the data – that is, overfitting is avoided. Formally, let <span class="math inline">ERM<sub>ℋ</sub></span> uses ERM to learn <span class="math inline"><em>h</em> : 𝒳 → 𝒴</span> over <span class="math inline">$h \in {\cal H}$</span> by using the training data <span class="math inline"><em>S</em></span>: <span class="math display">$$\operatorname{ERM}_{\mathcal{H}}(S) \in \underset{h \in \mathcal{H}}{\operatorname{argmin}} L_{S}(h).$$</span> In other words, we are now minimizing a constrained empirical risk. Ideally, the choice of <span class="math inline">ℋ</span> should be governed by knowledge of data. But even “simple” choices of <span class="math inline">ℋ</span> can overfit if we are not careful. Of course, overly strong inductive bias can lead to underfitting. How to balance between the overfit and underfit is precisely the job of learning designers.</p> <h2 id="loss-function-erm-setup"> <a href="#loss-function-erm-setup" class="anchor-heading" aria-labelledby="loss-function-erm-setup"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Loss function, ERM setup </h2> <p>Now let us write the ERM as a mathematical problem. Recall, risk is defined as <span class="math display"><em>L</em>(<em>h</em>) = ℙ(<em>h</em>(<em>X</em>)≠<em>Y</em>).</span> Here we introduce a generic framework that encapsulates variety of “risks”. To that end, consider a loss function <span class="math display">ℓ : ℋ × 𝒳 × 𝒴 → ℝ<sub>+</sub>.</span> Then, the risk can then be written as the expected loss upon using <span class="math inline"><em>h</em> ∈ ℋ</span> with respect to the data distribution <span class="math inline">ℙ</span>. Thus, <span class="math display"><em>L</em>(<em>h</em>) := 𝔼[ℓ(<em>h</em>,<em>X</em>,<em>Y</em>)].</span> Similarly, the empirical risk is using <span class="math inline"><em>N</em></span> data points is <span class="math display">$$\label{eq:5} L_{S}(h) :=\frac{1}{N} \sum_{i=1}^{N} \ell\left(h, x_{i}, y_{i}\right).$$</span> The classification risk we have considered thus far corresponds to 0/1-loss: <span class="math display">$$\ell_{0 / 1}(h,x, y) :=\left\{\begin{array}{ll}{1,} &amp; {h(x) \neq y} \\ {0,} &amp; {h(x)=y},\end{array}\right.$$</span> which incurs a loss of <span class="math inline">1</span> if the current data is mis-classified. When we shall discuss regression, we will introduce different (squared) loss.</p> <div class="center"> </div> <p>Under the <span class="math inline">0/1</span>-loss, the task of ERM reduces to the computational question: <span class="math display">$$\min _{h \in \mathcal{H}} \frac{1}{N} \sum_{i=1}^{N} \ell_{0 / 1}\left(h, x_{i}, y_{i}\right)=\frac{1}{N} \sum_{i=1}^{N}\left\llbracket h\left(x_{i}\right) \neq y_{i}\right\rrbracket.\label{eq:6}$$</span> This empirical risk minimization is typically computationally hard. One way to get around the computational hardness is to utilize surrogate for 0/1-loss that leads to computational simplicity. For example, support vector machine that shall be covered in future lecture, the computationally feasible surrogate of 0/1-loss turns out to be the so called “hinge loss”.</p> <div class="center"> </div> <h2 id="erm-theory"> <a href="#erm-theory" class="anchor-heading" aria-labelledby="erm-theory"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> ERM: Theory </h2> <p>The ERM theory asks this question: <em>when does ERM work?</em> In other words, if we minimize the empirical risk <span class="math inline"><em>L</em><sub><em>S</em></sub>(<em>h</em>)</span>, what bearing does that have on the population risk <span class="math inline"><em>L</em>(<em>h</em>)</span>? The goal of learning theory is to study this (and such) question(s). Informally, if for all <span class="math inline"><em>h</em> ∈ ℋ</span>, the empirical risk <span class="math inline"><em>L</em><sub><em>S</em></sub>(<em>h</em>)</span> is a good approximation to <span class="math inline"><em>L</em>(<em>h</em>),</span> then ERM will also return a good hypothesis within <span class="math inline">${\cal H}$</span>, and we may be able to establish a bound of the form <span class="math display">$$\label{eq4} L_{\mathbb{P}}\left(\operatorname{ERM}_{\mathcal{H}}(S) \right) \leq \min _{h \in \mathcal{H}} L_{\mathbb{P}}(h) + \varepsilon(N, {\cal H}).$$</span> where recall that <span class="math inline">ERM<sub>ℋ</sub>(<em>S</em>)</span> is the classifier learned using ERM; both risks are taken over the data distribution as well as randomly generated <span class="math inline"><em>S</em></span> per the data distribution. If such is that case, then empirical risk of <span class="math inline">ERM<sub>ℋ</sub>(<em>S</em>)</span> will provide a good proxy of the best population risk achievable by <span class="math inline">${\cal H}$</span>. Naturally, larger <span class="math inline">${\cal H}$</span> we have better the best population risk minimization is achieved over <span class="math inline">${\cal H}$</span>; so what stops us from choosing very large <span class="math inline">${\cal H}$</span>?</p> <h2 id="erm-bias-complexity-tradeoff"> <a href="#erm-bias-complexity-tradeoff" class="anchor-heading" aria-labelledby="erm-bias-complexity-tradeoff"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> ERM: Bias-complexity tradeoff </h2> <p>At the highest level, typically the error <span class="math inline">$\varepsilon(N, {\cal H})$</span> in <a href="#eq4" data-reference-type="eqref" data-reference="eq4">[eq4]</a> increases with <span class="math inline">${\cal H}$</span> for a fixed <span class="math inline"><em>N</em></span>. And <span class="math inline">min<sub><em>h</em> ∈ ℋ</sub><em>L</em><sub>ℙ</sub>(<em>h</em>)</span> decreases as <span class="math inline">${\cal H}$</span> increases. That is, if we increase “complexity” of <span class="math inline">${\cal H}$</span>, then the ‘bias’, represented as <span class="math inline">min<sub><em>h</em> ∈ ℋ</sub><em>L</em><sub>ℙ</sub>(<em>h</em>)</span> decreases. But ‘variance’, represented as <span class="math inline">$\varepsilon(N, {\cal H})$</span> in <a href="#eq4" data-reference-type="eqref" data-reference="eq4">[eq4]</a> increases. The ultimate goal is to achieve the right trade-off between these two for a given number of data points, <span class="math inline"><em>N</em></span>.</p> <figure id="classic"> <img src="./classic-tradeoff.png" style="width:40.0%" alt="Classical training vs test curve. (Figure taken from: [@belkin2019reconciling].)" /> <figcaption aria-hidden="true">Classical training vs test curve. (Figure taken from: <span class="citation" data-cites="belkin2019reconciling">[@belkin2019reconciling]</span>.)</figcaption> </figure> <p>This bias-variance tradeoff or tension is captured by Figure <a href="#classic" data-reference-type="ref" data-reference="classic">1</a>. This is the classical view point. In the recent times, practitioners have found “rich” models e.g. over parametrized neural networks and empirically observed that once passed a certain complexity (of the model class <span class="math inline">ℋ</span>), beyond the so-called interpolation threshold point, the data can be fit perfectly as well as the generalization continues to improve. This is shown by the double-descent curve in Figure <a href="#modern-tradeoff" data-reference-type="ref" data-reference="modern-tradeoff">2</a>. It is believed that this behavior is similar to that of non-parametric method like the nearest neighbor that generalizes well for all setting with enough observations even through the corresponding model class is extremely rich.</p> <figure id="modern-tradeoff"> <img src="./modern-tradeoff.png" style="width:55.0%" alt="Modern training vs test curve. (Figure taken from: [@belkin2019reconciling].)" /> <figcaption aria-hidden="true">Modern training vs test curve. (Figure taken from: <span class="citation" data-cites="belkin2019reconciling">[@belkin2019reconciling]</span>.)</figcaption> </figure> <p><span style="color: cdarkred"><strong>Extra reading:</strong></span> all sections are from <span class="citation" data-cites="sss">[@sss]</span>:</p> <ul> <li><p>Definitions: §2.1,</p></li> <li><p>ERM and inductive bias: §2.2, §2.3,</p></li> <li><p>Loss function: §12.3, §3.2.2,</p></li> <li><p>Nearest neighbor §19.0, §19.1.</p></li> </ul> <aside id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr /> <ol> <li id="fn1"><p>These exercises are beyond those covered in recitation; they supplement the lecture material and notes, and it will be valuable for the reader to think about them carefully.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li> </ol> </aside> </main> <hr> <footer> Last updated: 16-Jun-2023 <p><a href="#top" id="back-to-top">Back to top</a></p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0"> <a href="https://shenshen.mit.edu/git/shensquared/gradml/tree/main/supervised/classification_foundation.md" id="edit-this-page">Edit this page on Git</a> </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html> <script src="https://hypothes.is/embed.js" async></script>
