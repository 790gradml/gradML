---
layout: page
title: Background/Review
nav_order: 3

---

# Backrgound and Review

## Notations

- Data matrix is of the size $$(n,d)$$ where $$n$$ is the number of data points, and $$d$$ is the dimension of the features
- Vectors are denoted with a small-case letter; matrices capital letters
- The default norm of a vector is the $$l_2$$ norm

## Linear algebra, calculus, and optimization

- Gradient vector
- Positive semi-definite (PSD) and positive definiteness (PD)
- Convexity, strong convexity

<!-- <iframe src = https://shenshen.mit.edu/demos/QuadraticFun.html style="width:100%; height: 100%"></iframe> -->
- Optimal solutions, uniqueness

## Probability theory and Statistics

### Concepts related to a single distribution

- Multi-variate normal distribution
- Max likelihood and Max log likelihood

### Concepts involving multiple distributions

- Marginal independence
  - Joint probability is the product
  - Entropy of the joint distribution is the sum of individual entropies
- Bayes' rule
- Conditional independence
  - Compare with marginal independence
- Importance sampling
- Jensen inequality
- KL divergence
