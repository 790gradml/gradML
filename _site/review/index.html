<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Background/Review | 6.790 Machine Learning</title> <meta name="generator" content="Jekyll v4.3.2" /> <meta property="og:title" content="Background/Review" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Graduate Machine Learning Course, MIT EECS, Fall 2023." /> <meta property="og:description" content="Graduate Machine Learning Course, MIT EECS, Fall 2023." /> <link rel="canonical" href="https://gradml.mit.edu/review/" /> <meta property="og:url" content="https://gradml.mit.edu/review/" /> <meta property="og:site_name" content="6.790 Machine Learning" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Background/Review" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","dateModified":"2023-06-19T15:00:08-04:00","description":"Graduate Machine Learning Course, MIT EECS, Fall 2023.","headline":"Background/Review","url":"https://gradml.mit.edu/review/"}</script> <!-- End Jekyll SEO tag --> <link rel="shortcut icon" type="image/png" href="/assets/images/favicon.png"> <!-- CSS --> <link rel="stylesheet" href="/assets/js/katex.min.css" /> <!-- JavaScript --> <script defer src="/assets/js/katex.min.js"></script> <script defer src="/assets/js/auto-render.min.js" onload="renderMathInElement(document.body,{ delimiters: [ { left: '$$', right: '$$', display: true }, { left: '$', right: '$', display: false }, { left: '\\[', right: '\\]', display: true }, { left: '\\(', right: '\\)', display: false } ] } );"> </script> <script src="/assets/js/hypothesis.js" async></script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> 6.790 <br> Machine Learning </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"> <use xlink:href="#svg-menu"></use> </svg> </a> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Info category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/" class="nav-list-link">Info</a><ul class="nav-list"><li class="nav-list-item "><a href="/info/calendar/" class="nav-list-link">Syllabus / Calendar</a></li><li class="nav-list-item "><a href="/info/staff/" class="nav-list-link">Staff</a></li><li class="nav-list-item "><a href="/info/schedule/" class="nav-list-link">Weekly Schedule</a></li><li class="nav-list-item "><a href="/info/grading/" class="nav-list-link">Grading and Late Policy</a></li></ul></li><li class="nav-list-item"><a href="/intro/" class="nav-list-link">Introduction</a></li><li class="nav-list-item active"><a href="/review/" class="nav-list-link active">Background/Review</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Supervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/supervised/" class="nav-list-link">Supervised Learning</a><ul class="nav-list"><li class="nav-list-item "><a href="/supervised/classification_fundamentals/" class="nav-list-link">Classification Fundamentals</a></li><li class="nav-list-item "><a href="/supervised/DiscriminativeGenerative/" class="nav-list-link">Discriminative vs Generative Classification</a></li><li class="nav-list-item "><a href="/supervised/learnability_and_vc/" class="nav-list-link">Learnability and VC Dimension</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Unsupervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/unsupervised/" class="nav-list-link">Unsupervised Learning</a><ul class="nav-list"><li class="nav-list-item "><button class="nav-list-expander btn-reset" aria-label="toggle items in Graphical Models category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/unsupervised/graphical/" class="nav-list-link">Graphical Models</a><ul class="nav-list"></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reinforcement Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/reinforcement/" class="nav-list-link">Reinforcement Learning</a><ul class="nav-list"><li class="nav-list-item "><a href="/reinforcement/mdp/" class="nav-list-link">Markov Decision Process</a></li><li class="nav-list-item "><a href="/reinforcement/value_bellman/" class="nav-list-link">Value functions and Bellman</a></li><li class="nav-list-item "><a href="/reinforcement/bandit/" class="nav-list-link">Bandits</a></li><li class="nav-list-item "><a href="/reinforcement/policy_gradient/" class="nav-list-link">Policy Gradient</a></li><li class="nav-list-item "><a href="/reinforcement/deepRL/" class="nav-list-link">Deep Reinforcement Learning</a></li></ul></li></ul> </nav> <footer class="site-footer"> <a href="/credit">Acknowledgement</a> </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search 6.790 Machine Learning" aria-label="Search 6.790 Machine Learning" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://canvas.mit.edu/" class="site-button" target="_blank" rel="noopener noreferrer" > Canvas </a> </li> <li class="aux-nav-list-item"> <a href="https://piazza.com" class="site-button" target="_blank" rel="noopener noreferrer" > Piazza </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <div id="main-content" class="main-content"> <p class="warning"> The site is under construction. </p> <main> <h1 class="no_toc" id="backrgound-and-review"> <a href="#backrgound-and-review" class="anchor-heading" aria-labelledby="backrgound-and-review"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Backrgound and Review </h1> <h2 class="no_toc text-delta" id="table-of-contents"> <a href="#table-of-contents" class="anchor-heading" aria-labelledby="table-of-contents"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Table of contents </h2> <ol id="markdown-toc"> <li><a href="#notations" id="markdown-toc-notations">Notations</a></li> <li><a href="#linear-algebra-calculus-and-optimization" id="markdown-toc-linear-algebra-calculus-and-optimization">Linear Algebra, Calculus, and Optimization</a> <ol> <li><a href="#the-gradient-vector" id="markdown-toc-the-gradient-vector">The Gradient Vector</a></li> <li><a href="#the-chain-rule-in-calculus" id="markdown-toc-the-chain-rule-in-calculus">The Chain Rule (in calculus)</a></li> <li><a href="#positive-semidefiniteness-psd-and-positive-definiteness-pd" id="markdown-toc-positive-semidefiniteness-psd-and-positive-definiteness-pd">Positive Semidefiniteness (PSD) and Positive Definiteness (PD)</a></li> <li><a href="#convexity-and-strong-convexity" id="markdown-toc-convexity-and-strong-convexity">Convexity and Strong Convexity</a></li> <li><a href="#optimal-solutions-and-uniqueness" id="markdown-toc-optimal-solutions-and-uniqueness">Optimal Solutions and Uniqueness</a></li> </ol> </li> <li><a href="#probability-and-statistics" id="markdown-toc-probability-and-statistics">Probability and Statistics</a> <ol> <li><a href="#concepts-related-to-a-single-distribution" id="markdown-toc-concepts-related-to-a-single-distribution">Concepts related to a single distribution</a> <ol> <li><a href="#basics-and-formulae" id="markdown-toc-basics-and-formulae">Basics and formulae</a></li> <li><a href="#fundamental-distributions" id="markdown-toc-fundamental-distributions">Fundamental Distributions</a></li> <li><a href="#jensens-inequality" id="markdown-toc-jensens-inequality">Jensen’s Inequality</a></li> <li><a href="#max-likelihood-and-max-log-likelihood" id="markdown-toc-max-likelihood-and-max-log-likelihood">Max likelihood and Max log likelihood</a></li> </ol> </li> <li><a href="#concepts-involving-multiple-distributions" id="markdown-toc-concepts-involving-multiple-distributions">Concepts involving multiple distributions</a> <ol> <li><a href="#conditional-probability" id="markdown-toc-conditional-probability">Conditional probability</a></li> <li><a href="#the-chain-rule-in-probability" id="markdown-toc-the-chain-rule-in-probability">The Chain Rule (in probability)</a></li> <li><a href="#marginal-independence" id="markdown-toc-marginal-independence">Marginal Independence</a></li> <li><a href="#bayes-rule" id="markdown-toc-bayes-rule">Bayes’ Rule</a></li> <li><a href="#conditional-independence" id="markdown-toc-conditional-independence">Conditional Independence</a></li> <li><a href="#importance-sampling" id="markdown-toc-importance-sampling">Importance sampling</a></li> <li><a href="#kl-divergence" id="markdown-toc-kl-divergence">KL divergence</a></li> </ol> </li> </ol> </li> </ol> <h1 id="notations"> <a href="#notations" class="anchor-heading" aria-labelledby="notations"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Notations </h1> <ul> <li>Data matrix is of the size $(n,d)$ where $n$ is the number of data points, and $d$ is the dimension of the features</li> <li>Vectors are denoted with a small-case letter; matrices capital letters</li> <li>The default norm of a vector is the $l_2$ norm</li> </ul> <h1 id="linear-algebra-calculus-and-optimization"> <a href="#linear-algebra-calculus-and-optimization" class="anchor-heading" aria-labelledby="linear-algebra-calculus-and-optimization"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Linear Algebra, Calculus, and Optimization </h1> <h2 id="the-gradient-vector"> <a href="#the-gradient-vector" class="anchor-heading" aria-labelledby="the-gradient-vector"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> The Gradient Vector </h2> <h2 id="the-chain-rule-in-calculus"> <a href="#the-chain-rule-in-calculus" class="anchor-heading" aria-labelledby="the-chain-rule-in-calculus"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> The Chain Rule (in calculus) </h2> <h2 id="positive-semidefiniteness-psd-and-positive-definiteness-pd"> <a href="#positive-semidefiniteness-psd-and-positive-definiteness-pd" class="anchor-heading" aria-labelledby="positive-semidefiniteness-psd-and-positive-definiteness-pd"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Positive Semidefiniteness (PSD) and Positive Definiteness (PD) </h2> <h2 id="convexity-and-strong-convexity"> <a href="#convexity-and-strong-convexity" class="anchor-heading" aria-labelledby="convexity-and-strong-convexity"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Convexity and Strong Convexity </h2> <p class="example">Quadratic functions’ Convexity Property</p> <iframe src="/demos/QuadraticFun.html" width="1000" height="800" async=""></iframe> <h2 id="optimal-solutions-and-uniqueness"> <a href="#optimal-solutions-and-uniqueness" class="anchor-heading" aria-labelledby="optimal-solutions-and-uniqueness"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Optimal Solutions and Uniqueness </h2> <h1 id="probability-and-statistics"> <a href="#probability-and-statistics" class="anchor-heading" aria-labelledby="probability-and-statistics"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Probability and Statistics </h1> <h2 id="concepts-related-to-a-single-distribution"> <a href="#concepts-related-to-a-single-distribution" class="anchor-heading" aria-labelledby="concepts-related-to-a-single-distribution"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Concepts related to a single distribution </h2> <h3 id="basics-and-formulae"> <a href="#basics-and-formulae" class="anchor-heading" aria-labelledby="basics-and-formulae"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Basics and formulae </h3> <ul> <li>The notions of random variable, expectation, variance, entropy.</li> <li>Union bounds</li> <li>Concentration inequalities: Markov’s Inequality, Chernoff bound, Hoeffding’s inequality <h3 id="fundamental-distributions"> <a href="#fundamental-distributions" class="anchor-heading" aria-labelledby="fundamental-distributions"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Fundamental Distributions </h3> </li> </ul> <p><strong>Discrete Distributions PMFs (Probability Mass Functions)</strong></p> <ul> <li> <p>Discrete <em>uniform</em> with parameters $a$ and $b$, where $a$ and $b$ are integers with $a&lt;b$. Here, \(p_X(k)=1 /(b-a+1), \quad k=a, a+1, \ldots, b,\) and $p_X(k)=0$, otherwise. (In the remaining examples, the qualification “ $p_X(k)=0$, otherwise,” will be omitted brevity.)</p> </li> <li> <p><em>Bernoulli</em> with parameter $p$, where $0 \leq p \leq 1$. Here, $p_X(0)=p, p_X(1)=$ $1-p$.</p> </li> <li> <p><em>Binomial</em> with parameters $n$ and $p$, where $n \in \mathbb{N}$ and $p \in[0,1]$. Here,</p> </li> </ul> \[p_X(k)=\left(\begin{array}{l} n \\ k \end{array}\right) p^k(1-p)^{n-k}, \quad k=0,1, \ldots, n\] <p><strong>Continuous Distributions PDFs (Probability Density Functions)</strong></p> <ul> <li>1D Gaussian</li> <li>Multivariate Gaussian</li> </ul> <h3 id="jensens-inequality"> <a href="#jensens-inequality" class="anchor-heading" aria-labelledby="jensens-inequality"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Jensen’s Inequality </h3> <h3 id="max-likelihood-and-max-log-likelihood"> <a href="#max-likelihood-and-max-log-likelihood" class="anchor-heading" aria-labelledby="max-likelihood-and-max-log-likelihood"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Max likelihood and Max log likelihood </h3> <p class="example">MLE for Gaussian</p> <p>We have data $x_1,\ldots,x_N$ sampled from a distribution. The goal is to learn the distribution. The assumption is that the data is generated from a Gaussian distribution $\mathcal{N}(\mu,\sigma^2)$. Then the refined goal is to learn the mean and variance. How to learn (parameters, mean and variance)?</p> <p>A common method is maximum likelihood (ML), that is, choose the parameters that maximize $\mathbb{P}(\text{data}|\text{parameters})$. In this problem, to choose mean, variance from samples, the likelihood is</p> \[\begin{aligned} \mathbb{P}\left(x_1,\ldots,x_N|\mu,\sigma^2\right)=&amp;\prod_{i=1}^N\mathbb{P}\left(x_i|\mu,\sigma^2\right) \\ =&amp;\prod_{i=1}^N \frac{1}{(2\pi\sigma^2)^{1/2}}\exp\left(-\frac{(x_i-\mu)^2}{2\sigma^2}\right). \end{aligned}\] <p>Maximizing likelihood is same as maximizing logarithm of likelihood. This leads to</p> \[\max_{\mu,\sigma^2} g(\mu,\sigma^2),\] <p>where \(g(\mu,\sigma^2)=-\frac{1}{2\sigma^2}\sum_{i=1}^N(x_i-\mu)^2-N\ln\sigma -N\ln\sqrt{2\pi}.\) This is an optimization problem and its solution is what we desire. For such reasons, optimization is an integral part of Machine Learning. The ML estimation for variance (and standard deviation) is biased. This leads to the Bessel’s correction for variance:</p> \[\tilde{\sigma}^2_{\rm ML}=\frac{1}{N-1}\sum_{i=1}^N (x_i-\mu_{\rm ML})^2.\] <h2 id="concepts-involving-multiple-distributions"> <a href="#concepts-involving-multiple-distributions" class="anchor-heading" aria-labelledby="concepts-involving-multiple-distributions"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Concepts involving multiple distributions </h2> <h3 id="conditional-probability"> <a href="#conditional-probability" class="anchor-heading" aria-labelledby="conditional-probability"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Conditional probability </h3> <p>Consider a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, and an event $B \in \mathcal{F}$ with $\mathbb{P}(B)&gt;0$. For every event $A \in \mathcal{F}$, the conditional probability that $A$ occurs given that $B$ occurs is denoted by $\mathbb{P}(A \mid B)$ and is defined by</p> \[\mathbb{P}(A \mid B)=\frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}.\] <h3 id="the-chain-rule-in-probability"> <a href="#the-chain-rule-in-probability" class="anchor-heading" aria-labelledby="the-chain-rule-in-probability"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> The Chain Rule (in probability) </h3> <h3 id="marginal-independence"> <a href="#marginal-independence" class="anchor-heading" aria-labelledby="marginal-independence"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Marginal Independence </h3> <p>Let $(\Omega, \mathcal{F} \cdot \mathbb{P})$ be a probability space. Two events, $A$ and $B$, are said to be independent if $\mathbb{P}(A \cap B)=\mathbb{P}(A) \mathbb{P}(B)$. If $\mathbb{P}(B)&gt;0$, an equivalent condition is $\mathbb{P}(A)=\mathbb{P}(A \mid B)$.</p> <p>Note: As an immediate consequence of that joint probability is the product of individual probabilities, the entropy of the joint distribution is the sum of individual entropies</p> <h3 id="bayes-rule"> <a href="#bayes-rule" class="anchor-heading" aria-labelledby="bayes-rule"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Bayes’ Rule </h3> <p>Let $A$ be an event with $\mathbb{P}(A)&gt;0$. If the events $B_i, i \in \mathbb{N}$, form a partition of $\Omega$, and $\mathbb{P}\left(B_i\right)&gt;0$ for every $i$, then</p> \[\mathbb{P}\left(B_i \mid A\right)=\frac{\mathbb{P}\left(B_i\right) \mathbb{P}\left(A \mid B_i\right)}{\mathbb{P}(A)}=\frac{\mathbb{P}\left(B_i\right) \mathbb{P}\left(A \mid B_i\right)}{\sum_{j=1}^{\infty} \mathbb{P}\left(B_j\right) \mathbb{P}\left(A \mid B_j\right)}\] <h3 id="conditional-independence"> <a href="#conditional-independence" class="anchor-heading" aria-labelledby="conditional-independence"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Conditional Independence </h3> <ul> <li>Comparison with marginal independence</li> </ul> <h3 id="importance-sampling"> <a href="#importance-sampling" class="anchor-heading" aria-labelledby="importance-sampling"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> Importance sampling </h3> <h3 id="kl-divergence"> <a href="#kl-divergence" class="anchor-heading" aria-labelledby="kl-divergence"><svg viewBox="0 0 16 16" aria-hidden="true"> <use xlink:href="#svg-link"></use> </svg></a> KL divergence </h3> </main> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0"> <a href="https://shenshen.mit.edu/git/shensquared/gradml/tree/main/review.md" id="edit-this-page">Edit this page on Git</a> | This page was last updated on 19-Jun-2023 </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
